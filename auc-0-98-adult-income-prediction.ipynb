{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":472,"sourceType":"datasetVersion","datasetId":222}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Adult income prediction**","metadata":{}},{"cell_type":"markdown","source":"## **Leonardo Cofone**","metadata":{}},{"cell_type":"markdown","source":"**In this project, I worked on building a machine learning model for a binary classification task using a stacking ensemble approach. I combined several classifiers, including Random Forest, Gradient Boosting, and XGBoost, with AdaBoost as the final estimator to improve performance. I handled data preprocessing by setting up a pipeline that included steps like imputation, feature scaling, and encoding. To evaluate the model, I used various metrics like precision, recall, F1 score, and AUC. Finally, I fine-tuned the threshold using Youden's J statistic, which helped improve recall without sacrificing precision.**","metadata":{}},{"cell_type":"code","source":"#install old libraries for compatibility\n!pip uninstall -y scikit-learn > /dev/null 2>&1\n!pip uninstall -y category-encoders > /dev/null 2>&1\n!pip uninstall -y imbalanced-learn > /dev/null 2>&1\n\n!pip install scikit-learn==1.1.3 > /dev/null 2>&1\n!pip install imbalanced-learn==0.9.1 > /dev/null 2>&1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:46.197380Z","iopub.execute_input":"2025-05-10T15:57:46.197656Z","iopub.status.idle":"2025-05-10T15:57:58.993254Z","shell.execute_reply.started":"2025-05-10T15:57:46.197637Z","shell.execute_reply":"2025-05-10T15:57:58.992153Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Now the setup it's ready!!**","metadata":{}},{"cell_type":"markdown","source":"## **1) Analyze and work on data**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata = pd.read_csv('/kaggle/input/adult-income-dataset/adult.csv', na_values=\"?\")\ndata[\"income\"] = data[\"income\"].map({\"<=50K\": 0, \">50K\": 1})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:58.995250Z","iopub.execute_input":"2025-05-10T15:57:58.995598Z","iopub.status.idle":"2025-05-10T15:57:59.117334Z","shell.execute_reply.started":"2025-05-10T15:57:58.995563Z","shell.execute_reply":"2025-05-10T15:57:59.116686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.118075Z","iopub.execute_input":"2025-05-10T15:57:59.118336Z","iopub.status.idle":"2025-05-10T15:57:59.131391Z","shell.execute_reply.started":"2025-05-10T15:57:59.118315Z","shell.execute_reply":"2025-05-10T15:57:59.130770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.133120Z","iopub.execute_input":"2025-05-10T15:57:59.133817Z","iopub.status.idle":"2025-05-10T15:57:59.170677Z","shell.execute_reply.started":"2025-05-10T15:57:59.133799Z","shell.execute_reply":"2025-05-10T15:57:59.170041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.171586Z","iopub.execute_input":"2025-05-10T15:57:59.171874Z","iopub.status.idle":"2025-05-10T15:57:59.203060Z","shell.execute_reply.started":"2025-05-10T15:57:59.171846Z","shell.execute_reply":"2025-05-10T15:57:59.202252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.203922Z","iopub.execute_input":"2025-05-10T15:57:59.204649Z","iopub.status.idle":"2025-05-10T15:57:59.229064Z","shell.execute_reply.started":"2025-05-10T15:57:59.204624Z","shell.execute_reply":"2025-05-10T15:57:59.228300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.229989Z","iopub.execute_input":"2025-05-10T15:57:59.230304Z","iopub.status.idle":"2025-05-10T15:57:59.241272Z","shell.execute_reply.started":"2025-05-10T15:57:59.230284Z","shell.execute_reply":"2025-05-10T15:57:59.240655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.242091Z","iopub.execute_input":"2025-05-10T15:57:59.242371Z","iopub.status.idle":"2025-05-10T15:57:59.286462Z","shell.execute_reply.started":"2025-05-10T15:57:59.242348Z","shell.execute_reply":"2025-05-10T15:57:59.285820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Take away those duplicates\ndata.drop_duplicates(inplace=True) \ndata.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.287199Z","iopub.execute_input":"2025-05-10T15:57:59.287418Z","iopub.status.idle":"2025-05-10T15:57:59.347540Z","shell.execute_reply.started":"2025-05-10T15:57:59.287401Z","shell.execute_reply":"2025-05-10T15:57:59.346826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check if the classes are unbalanced\nprint(pd.Series(data[\"income\"]).value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.349374Z","iopub.execute_input":"2025-05-10T15:57:59.349616Z","iopub.status.idle":"2025-05-10T15:57:59.356872Z","shell.execute_reply.started":"2025-05-10T15:57:59.349598Z","shell.execute_reply":"2025-05-10T15:57:59.356001Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**The classes are really unbalanced**","metadata":{}},{"cell_type":"code","source":"#Try to balance the classes\nfrom sklearn.model_selection import train_test_split \nfrom imblearn.over_sampling import RandomOverSampler\n\nX=data.drop(['income'],axis=1)\ny=data['income']\nX_over,y_over=RandomOverSampler().fit_resample(X,y)\n\nX_train_full, X_test, y_train_full, y_test = train_test_split(X_over, y_over, test_size=0.1, random_state=42, stratify=y_over)\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1111, random_state=42, stratify=y_train_full)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.357613Z","iopub.execute_input":"2025-05-10T15:57:59.357873Z","iopub.status.idle":"2025-05-10T15:57:59.532435Z","shell.execute_reply.started":"2025-05-10T15:57:59.357856Z","shell.execute_reply":"2025-05-10T15:57:59.531888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Double check if the classes are balanced\nprint(pd.Series(y_train).value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.533255Z","iopub.execute_input":"2025-05-10T15:57:59.533472Z","iopub.status.idle":"2025-05-10T15:57:59.539033Z","shell.execute_reply.started":"2025-05-10T15:57:59.533455Z","shell.execute_reply":"2025-05-10T15:57:59.538295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Find out which features are categorical, numerical or heavy-tailed\ncategorical_cols = X_train.select_dtypes(include='object').columns\nnumeric_cols = X_train.select_dtypes(include=np.number).columns\n\nprint(\"Categorical features: \", categorical_cols)\nprint(\"Numerical features: \", numeric_cols)\n\nfrom scipy.stats import skew\nnumeric_cols = X_train.select_dtypes(include=np.number).columns\nskewed_feats = X_train[numeric_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewed_features = skewed_feats[skewed_feats > 0.8].index.tolist()\nskewed_features = [col for col in skewed_features if col in X_train.columns]\n\nprint(\"High skew features:\", skewed_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.539859Z","iopub.execute_input":"2025-05-10T15:57:59.540135Z","iopub.status.idle":"2025-05-10T15:57:59.583597Z","shell.execute_reply.started":"2025-05-10T15:57:59.540116Z","shell.execute_reply":"2025-05-10T15:57:59.582935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **2) Create a pipeline for a better preprocessing**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_selector\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\nfrom sklearn.impute import SimpleImputer\n\nlog_transformer = make_pipeline(                      \n    SimpleImputer(strategy=\"median\"),\n    FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\"),\n    StandardScaler()\n)\n\nnumeric_transformer = make_pipeline(              \n    SimpleImputer(strategy=\"median\"),\n    StandardScaler()\n)\n\ncategorical_transformer = make_pipeline(                       \n    SimpleImputer(strategy=\"most_frequent\"),\n    OneHotEncoder(handle_unknown=\"ignore\")\n)\n\n\npreprocessor = ColumnTransformer([                       \n    (\"log\", log_transformer, skewed_features),\n    \n    (\"num\", numeric_transformer, list(set(numeric_cols) - set(skewed_features))),\n\n    (\"cat\", categorical_transformer, categorical_cols),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:57:59.584382Z","iopub.execute_input":"2025-05-10T15:57:59.584966Z","iopub.status.idle":"2025-05-10T15:57:59.590174Z","shell.execute_reply.started":"2025-05-10T15:57:59.584941Z","shell.execute_reply":"2025-05-10T15:57:59.589477Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **3) Train and evaluate different model**","metadata":{}},{"cell_type":"markdown","source":"#### **Logistic Regression**","metadata":{}},{"cell_type":"code","source":"#TRAIN A LOGISTIC REGRESSION MODEL\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve\n\nlog_reg = Pipeline([\n    (\"preprocessor1\", preprocessor),\n    (\"log_reg\", LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')),\n])\n\nlog_reg.fit(X_train, y_train)\n\n#EVALUATE THE MODEL\nfrom sklearn.model_selection import cross_val_predict\ny_val_pred_1 = log_reg.predict(X_val)\n\nprint(\"Confusion Matrix For Logistic Regression:\\n\", confusion_matrix(y_val, y_val_pred_1))\n\nprint(f\"Precision: { precision_score(y_val, y_val_pred_1)}\")\nprint(f\"Recall: {recall_score(y_val, y_val_pred_1)}\")\nprint(f\"F1 Score: {f1_score(y_val, y_val_pred_1)}\")\n\ny_val_pred_proba_1 = log_reg.predict_proba(X_val)[:, 1]\nprint(f\"ROC AUC Score: {roc_auc_score(y_val, y_val_pred_proba_1)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:58:15.291604Z","iopub.execute_input":"2025-05-10T15:58:15.292340Z","iopub.status.idle":"2025-05-10T15:58:17.972256Z","shell.execute_reply.started":"2025-05-10T15:58:15.292314Z","shell.execute_reply":"2025-05-10T15:58:17.971496Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Gradient Boosting CLassifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngb_model = Pipeline([\n    (\"preprocessor1\", preprocessor),\n    (\"gb\", GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42))\n])\n\ngb_model.fit(X_train, y_train)\n\ny_val_pred_4 = gb_model.predict(X_val)\n\nprint(\"Confusion Matrix For Gradient Boosting:\\n\", confusion_matrix(y_val, y_val_pred_4))\nprint(f\"Precision: {precision_score(y_val, y_val_pred_4)}\")\nprint(f\"Recall: {recall_score(y_val, y_val_pred_4)}\")\nprint(f\"F1 Score: {f1_score(y_val, y_val_pred_4)}\")\n\ny_val_pred_proba_4 = gb_model.predict_proba(X_val)[:, 1]\nprint(f\"ROC AUC Score: {roc_auc_score(y_val, y_val_pred_proba_4)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:02:21.400501Z","iopub.execute_input":"2025-05-10T16:02:21.401059Z","iopub.status.idle":"2025-05-10T16:02:37.414799Z","shell.execute_reply.started":"2025-05-10T16:02:21.401036Z","shell.execute_reply":"2025-05-10T16:02:37.414033Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **XGB CLassifier**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_model = Pipeline([\n    (\"preprocessor1\", preprocessor),\n    (\"xgb\", XGBClassifier(n_estimators=200, learning_rate=0.1, use_label_encoder=False, eval_metric=\"logloss\", random_state=42))\n])\nxgb_model.fit(X_train, y_train)\n\ny_val_pred_3 = xgb_model.predict(X_val)\n\nprint(\"Confusion Matrix For XGBClassifier:\\n\", confusion_matrix(y_val, y_val_pred_3))\nprint(f\"Precision: {precision_score(y_val, y_val_pred_3)}\")\nprint(f\"Recall: {recall_score(y_val, y_val_pred_3)}\")\nprint(f\"F1 Score: {f1_score(y_val, y_val_pred_3)}\")\n\ny_val_pred_proba_3 = xgb_model.predict_proba(X_val)[:, 1]\nprint(f\"ROC AUC Score: {roc_auc_score(y_val, y_val_pred_proba_3)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:01:39.284301Z","iopub.execute_input":"2025-05-10T16:01:39.285081Z","iopub.status.idle":"2025-05-10T16:01:40.728897Z","shell.execute_reply.started":"2025-05-10T16:01:39.285055Z","shell.execute_reply":"2025-05-10T16:01:40.727904Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Random Forest Classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = Pipeline([\n    (\"preprocessor1\", preprocessor),\n    (\"rf\", RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced'))\n])\n\nrf_model.fit(X_train, y_train)\n\ny_val_pred_2 = rf_model.predict(X_val)\n\nprint(\"Confusion Matrix For Random Forest:\\n\", confusion_matrix(y_val, y_val_pred_2))\nprint(f\"Precision: {precision_score(y_val, y_val_pred_2)}\")\nprint(f\"Recall: {recall_score(y_val, y_val_pred_2)}\")\nprint(f\"F1 Score: {f1_score(y_val, y_val_pred_2)}\")\n\ny_val_pred_proba_2 = rf_model.predict_proba(X_val)[:, 1]\nprint(f\"ROC AUC Score: {roc_auc_score(y_val, y_val_pred_proba_2)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:58:34.798023Z","iopub.execute_input":"2025-05-10T15:58:34.798607Z","iopub.status.idle":"2025-05-10T16:00:44.280026Z","shell.execute_reply.started":"2025-05-10T15:58:34.798586Z","shell.execute_reply":"2025-05-10T16:00:44.279367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **4) Ensemble the three best models**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier,  AdaBoostClassifier\n\nrf_pipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"rf\", RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced'))\n])\n\nxgb_pipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"xgb\", XGBClassifier(n_estimators=200, learning_rate=0.1,\n                          use_label_encoder=False, eval_metric=\"logloss\", random_state=42))\n])\n\ngb_pipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"gb\", GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42))\n])\n\nstack_model = StackingClassifier(\n    estimators=[\n        ('rf', rf_pipeline),\n        ('xgb', xgb_pipeline),\n        ('gb', gb_pipeline),\n    ],\n    final_estimator=AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42),\n    cv=5,\n    n_jobs=-1\n)\n\nstack_model.fit(X_train, y_train)\n\ny_val_pred_5 = stack_model.predict(X_val)\n\nprint(\"Confusion Matrix For Stacking:\\n\", confusion_matrix(y_val, y_val_pred_5))\nprint(f\"Precision: {precision_score(y_val, y_val_pred_5)}\")\nprint(f\"Recall: {recall_score(y_val, y_val_pred_5)}\")\nprint(f\"F1 Score: {f1_score(y_val, y_val_pred_5)}\")\n\ny_val_pred_proba_5 = stack_model.predict_proba(X_val)[:, 1]\nprint(f\"ROC AUC Score: {roc_auc_score(y_val, y_val_pred_proba_5)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:13:30.321704Z","iopub.execute_input":"2025-05-10T16:13:30.321998Z","iopub.status.idle":"2025-05-10T16:20:21.102922Z","shell.execute_reply.started":"2025-05-10T16:13:30.321976Z","shell.execute_reply":"2025-05-10T16:20:21.102033Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **5) Final test on the test set**","metadata":{}},{"cell_type":"code","source":"y_test_pred_ST = stack_model.predict(X_test)\n\nprint(f\"Confusion matrix for stacking classifier:\\n {confusion_matrix(y_test, y_test_pred_ST)}\")\nprint(f\"Recall: {recall_score(y_test, y_test_pred_ST)}\")\nprint(f\"Precision:  {precision_score(y_test, y_test_pred_ST)}\")\nprint(f\"F1 Score: {f1_score(y_test, y_test_pred_ST)}\")\nprint(\"Classification Report, Stacking Classifier:\")\nprint(classification_report(y_test, y_test_pred_ST))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:23:37.820932Z","iopub.execute_input":"2025-05-10T16:23:37.821463Z","iopub.status.idle":"2025-05-10T16:23:38.476047Z","shell.execute_reply.started":"2025-05-10T16:23:37.821440Z","shell.execute_reply":"2025-05-10T16:23:38.475278Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **6) Threshold tuning**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ny_test_proba = stack_model.predict_proba(X_test)[:, 1]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\nroc_auc = roc_auc_score(y_test, y_test_proba)\nprint(f\"AUC Score: {roc_auc:.4f}\")\n\nplt.figure(figsize=(8,6))\nplt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='red', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend()\nplt.grid()\nplt.show()\n\nJ_scores = tpr - fpr\nbest_threshold = thresholds[np.argmax(J_scores)]\nprint(f\"Best threshold based on Youden's J statistic: {best_threshold:.4f}\")\n\ny_test_pred_new_threshold = (y_test_proba >= best_threshold).astype(int)\n\nprint(f\"Confusion matrix at new threshold {best_threshold}:\\n {confusion_matrix(y_test, y_test_pred_new_threshold)}\")\nprint(f\"Recall: {recall_score(y_test, y_test_pred_new_threshold)}\")\nprint(f\"Precision: {precision_score(y_test, y_test_pred_new_threshold)}\")\nprint(f\"F1 Score: {f1_score(y_test, y_test_pred_new_threshold)}\")\nprint(classification_report(y_test, y_test_pred_new_threshold))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:24:03.528334Z","iopub.execute_input":"2025-05-10T16:24:03.528901Z","iopub.status.idle":"2025-05-10T16:24:04.453122Z","shell.execute_reply.started":"2025-05-10T16:24:03.528879Z","shell.execute_reply":"2025-05-10T16:24:04.452544Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **7) save the model**","metadata":{}},{"cell_type":"code","source":"import joblib\njoblib.dump({'model': stack_model, 'threshold': best_threshold}, 'stacking__final.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:26:25.299130Z","iopub.execute_input":"2025-05-10T16:26:25.299731Z","iopub.status.idle":"2025-05-10T16:26:25.662224Z","shell.execute_reply.started":"2025-05-10T16:26:25.299709Z","shell.execute_reply":"2025-05-10T16:26:25.661625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Thank you for watching my notebook!!!**","metadata":{}}]}
